{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Input sequence: \"Dream big and work for it\""
      ],
      "metadata": {
        "id": "kjxn0yMBEWcN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vPXQWt4mtsC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "  [[0.72, 0.45, 0.31], # Dream   (x^1)\n",
        "   [0.75, 0.20, 0.55], # big     (x^2)\n",
        "   [0.30, 0.80, 0.40], # and     (x^3)\n",
        "   [0.85, 0.35, 0.60], # work    (x^4)\n",
        "   [0.55, 0.15, 0.75], # for     (x^5)\n",
        "   [0.25, 0.20, 0.85]] # it      (x^6)\n",
        ")\n",
        "\n",
        "# Corresponding words\n",
        "words = ['Dream', 'big', 'and', 'work', 'for', 'it']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to generate the context vector for 2nd token"
      ],
      "metadata": {
        "id": "G0kLX4ZrEdDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = inputs[1]\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2\n",
        "print(x_2)\n",
        "print(d_in)\n",
        "print(d_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2P02qwBm7d5",
        "outputId": "3b57de4c-649b-43a6-e8bb-7605bff021dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7500, 0.2000, 0.5500])\n",
            "3\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly initializing Wq, Wk, Wv matrices"
      ],
      "metadata": {
        "id": "QeCC96iVElfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ],
      "metadata": {
        "id": "eAR-XKlUnRAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(W_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njl0MhPknXV2",
        "outputId": "e9108a3c-18b5-4649-94de-1d8fce3fccae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.2961, 0.5166],\n",
            "        [0.2517, 0.6886],\n",
            "        [0.0740, 0.8665]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(W_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk7qkrJCndd7",
        "outputId": "8d315ed1-269f-41d0-e867-a3be6cd7ec9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.1366, 0.1025],\n",
            "        [0.1841, 0.7264],\n",
            "        [0.3153, 0.6871]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(W_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyqRNQREnejn",
        "outputId": "928a596e-d1aa-4a05-e9bf-fcc163b61902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.0756, 0.1966],\n",
            "        [0.3164, 0.4017],\n",
            "        [0.1186, 0.8274]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "\n",
        "print(query_2)\n",
        "print(key_2)\n",
        "print(value_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk77_APungpi",
        "outputId": "4ea9a76b-9291-4a14-d3a0-ed9de82f9eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3131, 1.0017])\n",
            "tensor([0.3126, 0.6001])\n",
            "tensor([0.1852, 0.6829])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Q, K and V using X, Wq, Wk, Wv"
      ],
      "metadata": {
        "id": "yVVyCu7BEs67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "queries = inputs @ W_query\n",
        "\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "print(\"values.shape:\", values.shape)\n",
        "print(\"queries.shape:\", queries.shape)\n",
        "\n",
        "print(\"keys:\", keys)\n",
        "print(\"queries:\", queries)\n",
        "print(\"values:\", values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw83cmb_nkOw",
        "outputId": "9c2456e7-3e73-44af-f603-c4ebb9a9feae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys.shape: torch.Size([6, 2])\n",
            "values.shape: torch.Size([6, 2])\n",
            "queries.shape: torch.Size([6, 2])\n",
            "keys: tensor([[0.2789, 0.6137],\n",
            "        [0.3126, 0.6001],\n",
            "        [0.3143, 0.8867],\n",
            "        [0.3697, 0.7536],\n",
            "        [0.3392, 0.6807],\n",
            "        [0.3389, 0.7549]])\n",
            "queries: tensor([[0.3494, 0.9504],\n",
            "        [0.3131, 1.0017],\n",
            "        [0.3198, 1.0524],\n",
            "        [0.3842, 1.2000],\n",
            "        [0.2561, 1.0373],\n",
            "        [0.1872, 1.0034]])\n",
            "values: tensor([[0.2336, 0.5789],\n",
            "        [0.1852, 0.6829],\n",
            "        [0.3232, 0.7113],\n",
            "        [0.2462, 0.8042],\n",
            "        [0.1780, 0.7890],\n",
            "        [0.1830, 0.8328]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keys corresponding to second token and the attention of second token to itself"
      ],
      "metadata": {
        "id": "ENlgi_NdEyew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys_2 = keys[1] #A\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3ThdqYznoXt",
        "outputId": "3faf8812-2d33-4e75-fac9-702b4c3298fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6990)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All attention scores for query number 2"
      ],
      "metadata": {
        "id": "BlrcGM3jE9eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z6WjkE_nxpy",
        "outputId": "bb07c004-70c6-46db-a0f9-572ac2a7c947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7021, 0.6990, 0.9867, 0.8707, 0.7880, 0.8624])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention scores (NOT Weights) matrix"
      ],
      "metadata": {
        "id": "1ocXet45FARN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = queries @ keys.T # omega\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRtGC5f9n2Yj",
        "outputId": "c548bcc4-3ac3-4011-ff25-4d74b563ec67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6807, 0.6795, 0.9526, 0.8454, 0.7654, 0.8359],\n",
            "        [0.7021, 0.6990, 0.9867, 0.8707, 0.7880, 0.8624],\n",
            "        [0.7350, 0.7315, 1.0337, 0.9113, 0.8248, 0.9029],\n",
            "        [0.8436, 0.8402, 1.1848, 1.0464, 0.9471, 1.0361],\n",
            "        [0.7080, 0.7025, 1.0003, 0.8764, 0.7929, 0.8699],\n",
            "        [0.6680, 0.6606, 0.9486, 0.8254, 0.7465, 0.8210]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale by 1/sqrt(d) and then take softmax"
      ],
      "metadata": {
        "id": "ul1-uHaFFDNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
        "print(attn_scores_2)\n",
        "d_k = keys.shape[-1]\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
        "print(attn_weights_2)\n",
        "print(d_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFt-8kyGn5em",
        "outputId": "365163f9-0d67-4d06-86f3-5cb7d12a35d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7021, 0.6990, 0.9867, 0.8707, 0.7880, 0.8624])\n",
            "tensor([0.1531, 0.1528, 0.1873, 0.1725, 0.1627, 0.1715])\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax peaks when the numbers are scaled"
      ],
      "metadata": {
        "id": "cPfufM8AFIo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the tensor\n",
        "tensor = 8 * torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])\n",
        "scaled_tensor = tensor/8\n",
        "\n",
        "# Apply softmax without scaling\n",
        "softmax_result = torch.softmax(tensor, dim=-1)\n",
        "print(\"Softmax without scaling:\", softmax_result)\n",
        "\n",
        "# Multiply the tensor by 8 and then apply softmax\n",
        "softmax_scaled_result = torch.softmax(scaled_tensor, dim=-1)\n",
        "print(\"Softmax after scaling (tensor / 8):\", softmax_scaled_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUGoeLRsn-d0",
        "outputId": "d03045d1-c43c-47df-cec0-568ad082db2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax without scaling: tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n",
            "Softmax after scaling (tensor / 8): tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling has to be such that the variance of Q*K.T is close to 1"
      ],
      "metadata": {
        "id": "ILagQ9HaFNQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to compute variance before and after scaling\n",
        "def compute_variance(dim, num_trials=1000):\n",
        "    dot_products = []\n",
        "    scaled_dot_products = []\n",
        "\n",
        "    # Generate multiple random vectors and compute dot products\n",
        "    for _ in range(num_trials):\n",
        "        q = np.random.randn(dim)\n",
        "        k = np.random.randn(dim)\n",
        "\n",
        "        # Compute dot product\n",
        "        dot_product = np.dot(q, k)\n",
        "        dot_products.append(dot_product)\n",
        "\n",
        "        # Scale the dot product by sqrt(dim)\n",
        "        scaled_dot_product = dot_product / (dim)**0.5\n",
        "        scaled_dot_products.append(scaled_dot_product)\n",
        "\n",
        "    # Calculate variance of the dot products\n",
        "    variance_before_scaling = np.var(dot_products)\n",
        "    variance_after_scaling = np.var(scaled_dot_products)\n",
        "\n",
        "    return variance_before_scaling, variance_after_scaling\n",
        "\n",
        "# # For dimension 1\n",
        "# variance_before_1, variance_after_1 = compute_variance(1)\n",
        "# print(f\"Variance before scaling (dim=1): {variance_before_1}\")\n",
        "# print(f\"Variance after scaling (dim=1): {variance_after_1}\")\n",
        "\n",
        "# For dimension 128\n",
        "variance_before_5, variance_after_5 = compute_variance(5)\n",
        "print(f\"Variance before scaling (dim=5): {variance_before_5}\")\n",
        "print(f\"Variance after scaling (dim=5): {variance_after_5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3XStOztoDw0",
        "outputId": "960064bc-a9fd-45ce-ae4f-24fc01599d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance before scaling (dim=5): 5.367025473990419\n",
            "Variance after scaling (dim=5): 3.889910917988401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context vector corresponding to 2nd input token"
      ],
      "metadata": {
        "id": "o0oIH2pZFTq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores / d_k**0.5, dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJr98U2OfJ9Q",
        "outputId": "5464ac29-2050-4a5b-b0b0-beff23537471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1536, 0.1534, 0.1861, 0.1725, 0.1630, 0.1714],\n",
            "        [0.1531, 0.1528, 0.1873, 0.1725, 0.1627, 0.1715],\n",
            "        [0.1525, 0.1521, 0.1884, 0.1728, 0.1625, 0.1717],\n",
            "        [0.1505, 0.1501, 0.1915, 0.1737, 0.1619, 0.1724],\n",
            "        [0.1530, 0.1524, 0.1881, 0.1724, 0.1625, 0.1716],\n",
            "        [0.1538, 0.1530, 0.1875, 0.1719, 0.1625, 0.1713]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec_2 = attn_weights_2 @ values\n",
        "context_vec = attn_weights @ values\n",
        "print(context_vec_2)\n",
        "print(context_vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtJP4MVFoi_d",
        "outputId": "379aa18c-3906-43f3-e22c-796582f86c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2274, 0.7362])\n",
            "tensor([[0.2273, 0.7361],\n",
            "        [0.2274, 0.7362],\n",
            "        [0.2276, 0.7363],\n",
            "        [0.2280, 0.7368],\n",
            "        [0.2275, 0.7362],\n",
            "        [0.2275, 0.7360]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python class for doing this whole operation"
      ],
      "metadata": {
        "id": "AC4HqSEEFX8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_v1(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = x @ self.W_key\n",
        "        queries = x @ self.W_query\n",
        "        values = x @ self.W_value\n",
        "\n",
        "        attn_scores = queries @ keys.T # omega\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "t-EFh9qYok4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
        "print(sa_v1(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWc36qE3ospD",
        "outputId": "60136e9c-b472-484f-a782-a80fa1b2dc65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2273, 0.7361],\n",
            "        [0.2274, 0.7362],\n",
            "        [0.2276, 0.7363],\n",
            "        [0.2280, 0.7368],\n",
            "        [0.2275, 0.7362],\n",
            "        [0.2275, 0.7360]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        attn_scores = queries @ keys.T\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "V2sV-bnKovOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(789)\n",
        "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okYOlgRbo0zs",
        "outputId": "4ce5aaca-2d0f-47b1-c4fc-38a5149d9ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0184,  0.1495],\n",
            "        [-0.0180,  0.1502],\n",
            "        [-0.0183,  0.1495],\n",
            "        [-0.0178,  0.1505],\n",
            "        [-0.0177,  0.1506],\n",
            "        [-0.0177,  0.1507]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWxy0hqRjhah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}