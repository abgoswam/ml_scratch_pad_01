{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a65b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agoswami/miniconda3/envs/pt_0115_py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36303a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load tokenizer and explore chat template\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 2+2?\\nWhat is 4+4?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9478b709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:\n",
      " <|user|>\n",
      "What is 2+2?\n",
      "What is 4+4?<|end|>\n",
      "<|assistant|>\n",
      "\n",
      "Token count: 18\n",
      "Decoded: <|user|> What is 2+2?\n",
      "What is 4+4?<|end|><|assistant|>\n"
     ]
    }
   ],
   "source": [
    "# 2. Compare tokenize=True vs tokenize=False\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(\"Raw text:\\n\", text)\n",
    "\n",
    "token_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True)\n",
    "print(\"Token count:\", len(token_ids))\n",
    "print(\"Decoded:\", tokenizer.decode(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "480c6c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With special tokens: <|user|> What is 2+2?\n",
      "What is 4+4?<|end|><|assistant|>\n",
      "Without special tokens: What is 2+2?\n",
      "What is 4+4?\n"
     ]
    }
   ],
   "source": [
    "print(\"With special tokens:\", tokenizer.decode(token_ids, skip_special_tokens=False))\n",
    "print(\"Without special tokens:\", tokenizer.decode(token_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73545bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Raw text repr ===\n",
      "'<|user|>\\nWhat is 2+2?\\nWhat is 4+4?<|end|>\\n<|assistant|>\\n'\n",
      "\n",
      "=== Decoded repr ===\n",
      "'<|user|> What is 2+2?\\nWhat is 4+4?<|end|><|assistant|>'\n",
      "\n",
      "=== Token-by-token breakdown ===\n",
      "Token 0: id=32010 -> '<|user|>'\n",
      "Token 1: id= 1724 -> 'What'\n",
      "Token 2: id=  338 -> 'is'\n",
      "Token 3: id=29871 -> ''\n",
      "Token 4: id=29906 -> '2'\n",
      "Token 5: id=29974 -> '+'\n",
      "Token 6: id=29906 -> '2'\n",
      "Token 7: id=29973 -> '?'\n",
      "Token 8: id=   13 -> '\\n'\n",
      "Token 9: id= 5618 -> 'What'\n",
      "Token 10: id=  338 -> 'is'\n",
      "Token 11: id=29871 -> ''\n",
      "Token 12: id=29946 -> '4'\n",
      "Token 13: id=29974 -> '+'\n",
      "Token 14: id=29946 -> '4'\n",
      "Token 15: id=29973 -> '?'\n",
      "Token 16: id=32007 -> '<|end|>'\n",
      "Token 17: id=32001 -> '<|assistant|>'\n"
     ]
    }
   ],
   "source": [
    "# Investigate newline normalization around special tokens\n",
    "print(\"=== Raw text repr ===\")\n",
    "print(repr(text))\n",
    "print()\n",
    "print(\"=== Decoded repr ===\")\n",
    "print(repr(tokenizer.decode(token_ids)))\n",
    "print()\n",
    "\n",
    "# Look at individual tokens to see what happened to newlines\n",
    "print(\"=== Token-by-token breakdown ===\")\n",
    "for i, tid in enumerate(token_ids):\n",
    "    decoded = tokenizer.decode([tid])\n",
    "    print(f\"Token {i}: id={tid:5d} -> {repr(decoded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b56f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are they equal? False\n",
      "\n",
      "repr of text:\n",
      "'<|user|>\\nWhat is 2+2?\\nWhat is 4+4?<|end|>\\n<|assistant|>\\n'\n",
      "\n",
      "repr of decoded:\n",
      "'<|user|> What is 2+2?\\nWhat is 4+4?<|end|><|assistant|>'\n"
     ]
    }
   ],
   "source": [
    "# Check if they're actually different\n",
    "print(\"Are they equal?\", text == tokenizer.decode(token_ids))\n",
    "print()\n",
    "print(\"repr of text:\")\n",
    "print(repr(text))\n",
    "print()\n",
    "print(\"repr of decoded:\")\n",
    "print(repr(tokenizer.decode(token_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19fe5dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['question', 'answer']\n",
      "First example messages: [{'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "# 3. Load and process a dataset\n",
    "dataset = load_dataset(\"gsm8k\", \"main\", split=\"train[:100]\")\n",
    "print(\"Columns:\", dataset.column_names)\n",
    "\n",
    "def add_prompt(row):\n",
    "    row[\"messages\"] = [{\"role\": \"user\", \"content\": row[\"question\"]}]\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(add_prompt)\n",
    "print(\"First example messages:\", dataset[0][\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5216c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72',\n",
       " 'messages': [{'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       "   'role': 'user'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ab18d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:\n",
      " <|user|>\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|end|>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(dataset[0][\"messages\"], tokenize=False, add_generation_prompt=True)\n",
    "print(\"Raw text:\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d7c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_0115_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
