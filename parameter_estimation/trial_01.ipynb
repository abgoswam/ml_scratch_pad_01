{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706a0a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.7.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c47f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerBlock(\n",
      "  (att): MultiHeadAttention(\n",
      "    (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm()\n",
      "  (norm2): LayerNorm()\n",
      "  (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from gpt import TransformerBlock\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f54cf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:att.W_query.weight torch.Size([768, 768])\n",
      "name:att.W_key.weight torch.Size([768, 768])\n",
      "name:att.W_value.weight torch.Size([768, 768])\n",
      "name:att.out_proj.weight torch.Size([768, 768])\n",
      "name:att.out_proj.bias torch.Size([768])\n",
      "name:ff.layers.0.weight torch.Size([3072, 768])\n",
      "name:ff.layers.0.bias torch.Size([3072])\n",
      "name:ff.layers.2.weight torch.Size([768, 3072])\n",
      "name:ff.layers.2.bias torch.Size([768])\n",
      "name:norm1.scale torch.Size([768])\n",
      "name:norm1.shift torch.Size([768])\n",
      "name:norm2.scale torch.Size([768])\n",
      "name:norm2.shift torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for name, param in block.named_parameters():\n",
    "    print(f\"name:{name} {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8745098e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.8660e-03,  7.6987e-03, -1.9468e-03,  2.9360e-03, -2.1866e-03,\n",
      "         1.3394e-02,  7.6078e-03, -1.4768e-02, -2.5272e-03, -1.2794e-02,\n",
      "         1.7550e-02, -1.5238e-02, -7.0145e-03, -2.2412e-03, -4.6024e-03,\n",
      "         1.0892e-02,  1.3499e-02, -1.5189e-02, -1.5211e-02, -8.6266e-03,\n",
      "         1.2799e-02,  4.2199e-03,  3.2212e-03, -4.0765e-03,  5.2852e-03,\n",
      "         6.1208e-04,  4.1661e-03,  5.2963e-03, -6.1528e-03,  1.2753e-03,\n",
      "        -6.1978e-03, -1.3765e-02, -1.1962e-02, -1.4039e-03, -7.2276e-03,\n",
      "         1.4661e-02, -3.7850e-03,  5.3649e-03, -1.2704e-02,  1.1500e-02,\n",
      "         3.4307e-03, -2.4888e-04,  1.0896e-02, -1.7567e-02, -1.6188e-02,\n",
      "         5.7100e-03,  9.6828e-03, -1.1620e-02, -6.0314e-03, -8.4283e-03,\n",
      "        -1.1384e-02, -1.7943e-02,  1.5920e-02, -5.5909e-03,  1.4460e-03,\n",
      "         7.1554e-04,  6.2540e-03,  1.6037e-02, -1.1734e-02,  7.5017e-03,\n",
      "        -9.4770e-03, -4.1816e-03,  1.3061e-03, -1.5165e-02, -1.3627e-02,\n",
      "        -2.8658e-03, -1.5341e-02, -1.3703e-02, -5.7498e-03, -1.7759e-05,\n",
      "        -2.3490e-03, -9.5114e-03, -1.2411e-02, -1.5635e-02,  1.3349e-02,\n",
      "         2.4321e-03, -1.3819e-02, -2.9040e-04,  3.2692e-03, -1.6835e-02,\n",
      "         1.7625e-03,  6.5223e-03, -2.5371e-03, -1.6541e-02, -1.5080e-02,\n",
      "        -1.6895e-02,  2.1738e-03,  8.2380e-03,  1.2135e-02, -1.1792e-03,\n",
      "         3.4670e-03, -1.4167e-02,  1.1926e-02, -1.7981e-02, -1.3073e-02,\n",
      "         8.3553e-03,  7.5170e-03, -7.1896e-04,  1.4968e-02, -2.3218e-03,\n",
      "        -7.1508e-03,  1.3154e-02,  2.1172e-03, -1.1040e-02, -1.3749e-02,\n",
      "         1.1132e-02, -2.2911e-03, -4.4899e-03, -1.4466e-02, -1.6334e-02,\n",
      "         1.6440e-02,  1.5443e-03,  1.1604e-02, -1.1769e-02,  4.6375e-03,\n",
      "         1.2472e-02, -1.6956e-02,  1.2045e-02, -1.6439e-02,  2.9503e-03,\n",
      "        -1.3507e-02, -1.7281e-03,  1.1535e-02, -1.7772e-02,  1.7487e-02,\n",
      "        -1.4619e-02, -1.5657e-03,  3.6001e-03, -2.4201e-03,  5.1271e-03,\n",
      "         1.0141e-02, -2.6747e-03, -1.7262e-02,  1.1930e-02, -1.5069e-03,\n",
      "         1.4707e-02, -1.6887e-02,  5.4814e-03,  1.3831e-02, -1.0344e-02,\n",
      "        -4.8359e-03,  5.7275e-03, -1.2529e-02,  1.1019e-02, -1.1211e-02,\n",
      "        -1.2404e-02,  7.1490e-03,  1.4157e-02,  4.5616e-03,  1.4831e-02,\n",
      "        -1.2762e-02,  1.3604e-02,  1.6842e-02, -1.6312e-02, -9.4696e-03,\n",
      "         3.6704e-03,  4.8649e-03, -4.4032e-03,  9.3060e-03, -9.8396e-04,\n",
      "        -8.0085e-03,  1.3334e-02, -1.0083e-02, -8.3727e-03,  1.1073e-02,\n",
      "         1.2304e-02, -9.3800e-04, -5.9312e-04, -1.2368e-03,  1.6807e-02,\n",
      "         1.0847e-03,  3.8617e-03,  1.3498e-02, -2.1051e-03, -8.0931e-03,\n",
      "        -7.1714e-03,  3.6547e-03,  9.4244e-03, -2.4657e-03,  6.9174e-03,\n",
      "         1.7537e-02,  5.0416e-03, -1.2136e-02,  8.6571e-03,  9.9956e-03,\n",
      "        -1.6347e-02,  4.8184e-03,  1.3806e-02,  5.0857e-03,  9.1791e-04,\n",
      "         1.6640e-02, -1.1776e-02,  5.0554e-03, -1.0514e-02, -1.8022e-03,\n",
      "         1.1652e-02,  5.9871e-03,  4.2578e-03, -1.7894e-02, -1.1810e-02,\n",
      "        -7.9660e-03,  1.6614e-02, -1.3020e-03, -8.1497e-03,  1.5494e-02,\n",
      "        -3.3214e-04, -3.9530e-03,  1.2506e-02,  2.8121e-03, -6.9045e-03,\n",
      "        -1.5595e-02, -1.7130e-02,  1.3884e-02,  5.0885e-03,  1.3004e-02,\n",
      "         3.2845e-03,  1.8011e-02,  8.0237e-03, -6.6182e-04, -7.2034e-03,\n",
      "         3.4828e-03, -1.0806e-02,  3.3401e-03, -1.2063e-02, -9.2899e-03,\n",
      "         7.5189e-03,  1.1572e-02,  1.5073e-02,  1.6729e-02, -4.1100e-03,\n",
      "         1.1753e-02, -1.0152e-02,  1.1009e-02,  8.7281e-03,  1.1665e-02,\n",
      "         1.7388e-02,  1.4786e-02, -5.2472e-03,  3.9865e-03, -6.1137e-03,\n",
      "        -8.4375e-03,  3.1169e-03, -3.1668e-03, -1.7773e-02, -9.3349e-03,\n",
      "         1.0244e-02,  1.2401e-03, -1.0307e-02, -1.2119e-02, -1.1186e-02,\n",
      "         3.9926e-03, -1.5462e-03,  1.6678e-02,  9.4015e-03, -2.5412e-03,\n",
      "         7.2745e-03,  1.4424e-02,  6.7715e-03,  1.9850e-03,  4.0344e-03,\n",
      "         3.9192e-03,  3.7446e-03, -1.0417e-03, -1.5584e-02, -4.5108e-03,\n",
      "        -1.0623e-02, -1.1632e-02, -1.6169e-03,  7.7068e-03,  5.1734e-03,\n",
      "         1.1899e-02, -1.7499e-02, -7.4923e-03, -1.0035e-02,  1.4002e-02,\n",
      "        -6.6117e-03,  1.4070e-02,  1.4732e-02, -9.5801e-03, -1.2158e-02,\n",
      "         1.5393e-02, -1.2311e-02, -1.4134e-02,  1.6008e-02, -8.3588e-03,\n",
      "         5.3579e-03, -1.2883e-02, -7.0508e-03,  1.7617e-02, -6.4111e-03,\n",
      "         1.3249e-02,  1.1922e-02, -1.4142e-02,  5.2652e-05,  2.1330e-03,\n",
      "        -1.5962e-02,  1.6653e-02, -5.0109e-03,  9.5740e-03,  1.4012e-02,\n",
      "        -1.7232e-03,  2.8942e-03,  2.8739e-03,  7.6921e-03,  6.6651e-03,\n",
      "        -4.8850e-03,  1.7336e-02, -1.5803e-02, -1.8369e-03, -1.3312e-02,\n",
      "        -4.3903e-03,  1.8011e-03,  8.7910e-03, -1.1863e-02,  1.6575e-02,\n",
      "        -1.7726e-02,  2.3718e-03, -1.1067e-02,  9.7548e-03,  1.7507e-02,\n",
      "        -1.0520e-02,  1.0960e-02, -6.5005e-03,  2.6074e-03,  5.6282e-03,\n",
      "        -2.2944e-03,  5.7790e-03,  5.6984e-03, -1.6611e-02, -1.1501e-03,\n",
      "         9.4435e-03,  4.5595e-03, -6.7040e-03,  7.2914e-03,  8.7514e-03,\n",
      "         8.3549e-03,  1.5933e-02, -8.3061e-03,  6.6774e-03,  7.9184e-03,\n",
      "        -4.7260e-03, -2.8609e-03, -1.2058e-02, -7.2024e-03,  3.1747e-03,\n",
      "        -6.0209e-04,  3.1181e-03,  7.0954e-03,  1.7804e-02, -1.4583e-02,\n",
      "        -1.6412e-02, -1.4992e-02, -1.5981e-02,  1.3339e-02,  1.0083e-02,\n",
      "         1.8036e-02, -5.3185e-03, -1.4495e-02,  1.7059e-02,  1.5013e-02,\n",
      "        -1.5564e-02, -2.0270e-03,  2.7253e-03, -1.6709e-02,  5.6375e-03,\n",
      "         5.0063e-03,  1.1893e-02,  5.2483e-04,  1.0130e-03, -9.7436e-03,\n",
      "        -1.4314e-02, -9.0590e-03, -1.9100e-03, -7.7726e-03,  3.7038e-03,\n",
      "         1.7542e-02, -1.4723e-03, -1.6048e-02, -6.9477e-03, -5.4710e-03,\n",
      "        -1.7066e-02, -9.7976e-04,  1.5138e-03,  1.1950e-03,  1.6566e-02,\n",
      "        -1.6701e-03,  7.5340e-05, -5.3675e-03,  1.7658e-02, -2.9728e-03,\n",
      "        -6.1143e-03,  3.9802e-03, -1.7599e-03, -7.4856e-03, -4.4980e-03,\n",
      "         3.0750e-03,  6.2559e-03,  1.6003e-02, -9.9738e-03, -1.8760e-03,\n",
      "         4.4832e-03,  5.5165e-03,  1.1885e-02,  2.6185e-03, -1.7097e-02,\n",
      "        -1.5433e-02,  8.7936e-03, -4.1661e-03, -1.6949e-02,  8.8824e-03,\n",
      "        -2.4593e-03,  8.6360e-03, -3.1248e-03,  6.0871e-03,  1.3842e-02,\n",
      "         1.6952e-02,  4.9874e-03, -2.9688e-03, -3.2762e-03, -9.3746e-03,\n",
      "         1.1804e-02, -1.1749e-02,  2.5714e-03,  1.5967e-02,  1.2756e-02,\n",
      "        -2.8332e-04, -1.6913e-02,  3.1918e-03,  4.3384e-03, -4.1529e-03,\n",
      "         7.5621e-03,  8.9092e-04,  1.5565e-03,  1.5905e-02,  1.1242e-02,\n",
      "        -1.6901e-02, -1.0953e-02,  1.0981e-02, -1.6125e-02,  8.4369e-03,\n",
      "        -1.7178e-02, -2.2314e-03, -1.0910e-02, -8.3886e-04, -1.3634e-02,\n",
      "        -2.3211e-03,  1.6048e-03,  3.7907e-03, -8.9290e-03, -1.0394e-03,\n",
      "        -4.4490e-03,  1.0042e-02, -5.9644e-03, -1.3521e-02, -2.8702e-03,\n",
      "        -3.3248e-03, -1.5226e-02, -1.7269e-02,  3.0635e-04,  5.5473e-03,\n",
      "         8.7693e-03, -8.2441e-03,  1.4621e-02,  7.6421e-03,  1.1022e-02,\n",
      "         3.5695e-03, -1.3797e-02, -4.1450e-03,  2.1431e-03,  9.5097e-03,\n",
      "         1.6795e-02, -1.0185e-02, -2.7727e-03,  1.1385e-02, -1.2501e-02,\n",
      "         7.6293e-03, -1.9992e-03,  6.2730e-03,  5.0700e-03, -9.0321e-03,\n",
      "        -1.2544e-02,  1.3622e-02,  1.3365e-02, -9.9727e-03,  1.6783e-02,\n",
      "        -1.3414e-02, -1.4336e-02, -1.2081e-02,  2.0167e-03, -3.4498e-03,\n",
      "         1.4845e-02,  1.5857e-02, -1.2049e-02, -2.8049e-04,  6.5646e-03,\n",
      "        -1.3564e-02,  1.3894e-02,  1.6967e-02,  6.9627e-03,  1.6184e-02,\n",
      "        -4.6111e-04,  1.1141e-02,  1.5417e-02, -1.5679e-02, -1.7733e-03,\n",
      "        -1.0022e-04, -5.6018e-03,  1.1802e-02,  1.2163e-02, -1.6233e-03,\n",
      "        -5.6200e-03, -1.4411e-02,  4.6988e-03, -2.5678e-03,  6.2658e-03,\n",
      "        -2.2679e-03, -5.4781e-03,  1.0665e-02,  5.3598e-04,  1.6553e-02,\n",
      "         5.8419e-03, -1.5408e-02, -9.9095e-03,  1.6581e-02, -1.1304e-02,\n",
      "        -5.7728e-03,  8.1419e-03, -1.5352e-02, -3.1602e-03,  7.8800e-03,\n",
      "         3.6287e-03,  7.2713e-03, -9.1004e-03, -4.8557e-03,  2.2557e-03,\n",
      "         8.6381e-03, -1.5859e-02,  1.6216e-02,  1.2205e-02,  1.3331e-03,\n",
      "         6.7262e-03,  7.4185e-03, -1.5204e-02,  5.1424e-03, -1.6078e-02,\n",
      "         9.3834e-03, -1.2885e-02,  6.3590e-03,  1.7750e-02,  1.5489e-02,\n",
      "         8.0108e-03, -4.4878e-03, -1.0050e-02,  1.6613e-02,  1.0564e-02,\n",
      "        -1.1463e-02, -2.7405e-03,  8.6879e-03,  2.6295e-03, -5.6771e-04,\n",
      "         1.0322e-02,  1.4960e-02, -1.2956e-02,  1.6668e-02,  1.1313e-02,\n",
      "         9.4155e-03, -1.4297e-02,  1.2799e-02,  1.6989e-02, -1.7734e-02,\n",
      "         1.6715e-02,  6.2415e-03,  1.3988e-02,  6.3764e-03, -5.2940e-03,\n",
      "        -8.5911e-03,  2.9237e-03, -1.6634e-02, -2.4416e-03, -1.7311e-03,\n",
      "        -5.9621e-03,  4.9312e-03,  9.4724e-03,  7.1157e-03,  2.6287e-03,\n",
      "        -3.1265e-03, -1.8023e-02,  6.8108e-03,  2.0794e-03, -4.8731e-03,\n",
      "        -4.0786e-03,  1.0399e-02, -7.5602e-03, -2.3954e-03, -5.3434e-03,\n",
      "        -3.5082e-03,  1.1164e-02, -9.6343e-04, -1.0674e-02,  1.0417e-02,\n",
      "         3.5522e-03, -6.2768e-03,  1.6755e-02,  1.4242e-02, -3.4736e-03,\n",
      "        -1.5614e-02, -1.7053e-02,  5.7373e-03,  1.3439e-02,  9.9609e-03,\n",
      "        -1.3726e-02, -1.7308e-02,  1.7475e-02, -1.5471e-02, -1.7062e-02,\n",
      "         8.9816e-03, -6.5771e-03,  2.4554e-03,  6.0365e-03, -9.5675e-03,\n",
      "        -1.4510e-02,  1.7982e-02, -1.5577e-02,  1.5478e-02,  1.5161e-02,\n",
      "         1.1157e-02, -1.0111e-02, -1.6714e-02,  1.6035e-04, -4.9097e-03,\n",
      "         1.6981e-02, -1.5232e-02, -7.2626e-03,  5.5038e-03,  1.4024e-02,\n",
      "         5.6018e-03, -1.1467e-02, -1.6944e-02,  5.3146e-03, -2.5108e-03,\n",
      "         1.2869e-02, -4.1064e-03,  1.0434e-04,  2.0058e-03,  1.8298e-03,\n",
      "        -3.8479e-03, -2.4943e-04,  1.0065e-02, -2.0990e-03, -4.6504e-03,\n",
      "        -6.2894e-03,  3.0906e-03, -7.5950e-03, -6.7739e-03, -1.4676e-02,\n",
      "        -1.6215e-02,  8.6594e-03,  1.1361e-03,  8.5022e-03,  4.9876e-03,\n",
      "         2.3601e-03,  3.6615e-05,  1.5881e-02,  4.1287e-03, -1.0231e-02,\n",
      "        -1.4646e-02,  1.1829e-02, -7.5512e-04, -5.5411e-03,  7.9421e-03,\n",
      "         9.8424e-03,  1.1172e-02,  6.0151e-03,  2.9594e-03, -1.6575e-02,\n",
      "         1.1758e-02, -1.6980e-02, -1.0526e-02, -1.7594e-02, -2.5060e-03,\n",
      "         1.2305e-02, -1.5913e-02,  7.8274e-03, -1.6207e-02,  1.3463e-02,\n",
      "        -1.4825e-02, -8.7446e-03,  8.8649e-03,  1.5012e-02, -1.4705e-02,\n",
      "        -4.9600e-03,  1.7162e-02,  1.3106e-03, -3.8670e-03, -1.1991e-02,\n",
      "        -1.7264e-02, -7.5253e-03,  1.2717e-02, -8.3859e-03, -9.5329e-03,\n",
      "        -5.2391e-03,  7.3663e-03,  1.6139e-02,  3.8046e-03,  3.7876e-06,\n",
      "         2.2703e-03,  1.1345e-02,  6.4575e-04,  2.3192e-03, -1.5686e-02,\n",
      "         1.2288e-03,  1.5035e-02,  1.2903e-02, -2.6495e-03, -1.4714e-02,\n",
      "         4.7504e-03, -5.6367e-03,  3.1801e-03, -1.2511e-02, -1.1195e-02,\n",
      "         1.5343e-02,  1.4067e-02, -9.9613e-03,  1.1597e-02,  1.7653e-02,\n",
      "         6.0873e-03, -4.5744e-03,  5.6301e-03,  9.1648e-03, -1.1010e-02,\n",
      "        -3.5487e-03, -1.2648e-03,  1.3170e-04, -1.5809e-02, -8.4626e-03,\n",
      "        -5.1933e-03, -1.2097e-02, -1.4844e-03, -9.9131e-03, -7.1511e-03,\n",
      "         7.3988e-03, -2.8219e-03,  1.4509e-02,  4.5284e-03, -2.1866e-03,\n",
      "        -1.4507e-02,  1.6976e-02,  1.2393e-02, -1.5749e-03,  1.6552e-03,\n",
      "        -1.1724e-02, -6.4578e-03, -1.1706e-03, -1.2043e-02,  1.7603e-02,\n",
      "        -5.4645e-03,  1.6867e-02,  1.0181e-04, -1.5144e-02,  6.8475e-03,\n",
      "        -1.4493e-02, -7.0367e-03,  6.8030e-04, -5.1988e-03,  1.5353e-02,\n",
      "        -2.4576e-03, -1.2823e-02,  1.1576e-02])\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(param.data)\n",
    "print(param.grad)\n",
    "print(param.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd2c208a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:layers.0.weight torch.Size([3072, 768]) 2359296\n",
      "name:layers.0.bias torch.Size([3072]) 3072\n",
      "name:layers.2.weight torch.Size([768, 3072]) 2359296\n",
      "name:layers.2.bias torch.Size([768]) 768\n",
      "total_params_ff: 4722432\n"
     ]
    }
   ],
   "source": [
    "# parameters in ff layer.\n",
    "\n",
    "total_params_ff = 0\n",
    "for name, param in block.ff.named_parameters():\n",
    "    print(f\"name:{name} {param.shape} {param.numel()}\")\n",
    "    total_params_ff += param.numel()\n",
    "\n",
    "print(f\"total_params_ff: {total_params_ff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eed79b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: Parameter containing:\n",
      "tensor([[ 0.0269, -0.0357,  0.0185,  ...,  0.0225,  0.0077,  0.0098],\n",
      "        [ 0.0138,  0.0178, -0.0014,  ..., -0.0185,  0.0259,  0.0013],\n",
      "        [ 0.0018, -0.0109, -0.0175,  ..., -0.0296, -0.0310,  0.0069],\n",
      "        ...,\n",
      "        [-0.0221,  0.0220,  0.0075,  ...,  0.0160,  0.0090,  0.0129],\n",
      "        [-0.0188,  0.0214,  0.0054,  ..., -0.0273, -0.0259, -0.0176],\n",
      "        [ 0.0308, -0.0120,  0.0039,  ...,  0.0250,  0.0041, -0.0063]],\n",
      "       requires_grad=True)\n",
      "name:W_query.weight torch.Size([768, 768]) 589824\n",
      "param: Parameter containing:\n",
      "tensor([[-0.0186, -0.0168,  0.0238,  ...,  0.0282,  0.0206,  0.0032],\n",
      "        [-0.0162,  0.0246,  0.0093,  ..., -0.0042,  0.0003,  0.0118],\n",
      "        [-0.0324,  0.0263,  0.0020,  ...,  0.0292,  0.0176,  0.0265],\n",
      "        ...,\n",
      "        [-0.0347,  0.0154,  0.0333,  ..., -0.0017, -0.0148, -0.0141],\n",
      "        [-0.0323, -0.0197, -0.0047,  ..., -0.0031,  0.0094,  0.0072],\n",
      "        [ 0.0232,  0.0223,  0.0168,  ..., -0.0318, -0.0242,  0.0342]],\n",
      "       requires_grad=True)\n",
      "name:W_key.weight torch.Size([768, 768]) 589824\n",
      "param: Parameter containing:\n",
      "tensor([[-0.0004,  0.0234,  0.0314,  ..., -0.0312,  0.0019, -0.0348],\n",
      "        [ 0.0015, -0.0069,  0.0079,  ...,  0.0046,  0.0026, -0.0180],\n",
      "        [ 0.0245, -0.0359,  0.0176,  ..., -0.0022, -0.0324, -0.0048],\n",
      "        ...,\n",
      "        [ 0.0288,  0.0091,  0.0168,  ...,  0.0243, -0.0081,  0.0137],\n",
      "        [-0.0182, -0.0004, -0.0099,  ...,  0.0353, -0.0151, -0.0154],\n",
      "        [-0.0049, -0.0119, -0.0223,  ...,  0.0257,  0.0072,  0.0317]],\n",
      "       requires_grad=True)\n",
      "name:W_value.weight torch.Size([768, 768]) 589824\n",
      "param: Parameter containing:\n",
      "tensor([[-0.0062, -0.0298,  0.0086,  ...,  0.0052,  0.0227,  0.0325],\n",
      "        [-0.0134, -0.0024,  0.0316,  ...,  0.0222, -0.0089,  0.0154],\n",
      "        [ 0.0184, -0.0241,  0.0058,  ...,  0.0130, -0.0322, -0.0314],\n",
      "        ...,\n",
      "        [ 0.0288,  0.0165, -0.0319,  ...,  0.0067,  0.0241, -0.0354],\n",
      "        [ 0.0338, -0.0005, -0.0271,  ..., -0.0073,  0.0013, -0.0004],\n",
      "        [ 0.0073,  0.0257,  0.0271,  ..., -0.0092,  0.0004, -0.0270]],\n",
      "       requires_grad=True)\n",
      "name:out_proj.weight torch.Size([768, 768]) 589824\n",
      "param: Parameter containing:\n",
      "tensor([-3.4857e-02, -1.9062e-03,  2.8671e-02,  2.4478e-02,  1.2880e-02,\n",
      "         2.2415e-02,  1.5817e-02, -2.1026e-02, -3.1254e-02,  2.8560e-02,\n",
      "         1.5409e-02, -2.3042e-02,  1.3845e-02,  1.9409e-02,  2.1485e-02,\n",
      "         2.3208e-02,  2.8339e-02,  4.6815e-03, -2.7373e-02,  3.0828e-03,\n",
      "        -2.7737e-02, -2.1160e-02,  1.7008e-02,  3.0999e-02,  1.6635e-02,\n",
      "        -1.4393e-03,  1.1711e-02, -2.4541e-02,  5.9323e-03, -3.4895e-02,\n",
      "         1.0642e-02, -1.3789e-03, -1.9438e-02, -1.6850e-02, -2.1988e-02,\n",
      "        -1.6097e-02, -3.1325e-02,  4.2664e-03, -3.3411e-02, -1.2530e-02,\n",
      "        -2.7820e-03,  2.8998e-02, -1.4500e-02,  2.6897e-02, -1.7864e-02,\n",
      "         1.9456e-02,  2.1813e-03, -2.5804e-03, -6.1291e-03,  1.9781e-02,\n",
      "         7.2280e-04,  2.7517e-02, -3.7922e-04, -1.6793e-03,  2.6909e-02,\n",
      "         2.5725e-02, -6.3560e-03,  1.9404e-02,  2.1649e-02,  1.9969e-02,\n",
      "        -8.5810e-04, -6.4896e-03, -1.3766e-02,  1.0830e-02,  2.9733e-02,\n",
      "        -3.4075e-02,  1.3595e-02, -1.9904e-02, -3.2161e-03,  2.0306e-02,\n",
      "        -3.5992e-02, -1.6925e-02, -1.4484e-02, -2.4039e-02,  2.2966e-02,\n",
      "        -9.6913e-03, -7.6601e-03,  7.5394e-03, -2.0509e-02,  2.9675e-02,\n",
      "        -1.8385e-02, -2.4138e-02, -3.5159e-02, -1.9547e-02,  9.3651e-03,\n",
      "        -3.3357e-02, -4.7707e-03,  1.2084e-02,  7.8504e-03, -1.2215e-02,\n",
      "         3.0114e-03,  3.3509e-02, -1.0825e-02, -3.4282e-02,  3.5962e-02,\n",
      "        -9.6602e-03,  1.1419e-02,  1.9534e-02, -2.7025e-02,  5.4408e-03,\n",
      "         5.7618e-04, -3.2759e-02,  1.0854e-02, -1.5793e-02, -2.6523e-02,\n",
      "        -6.5297e-03, -4.9664e-03,  2.3539e-03, -3.4249e-02,  5.7593e-03,\n",
      "        -8.0374e-03, -1.2727e-02,  2.1129e-02, -1.0598e-02,  2.3883e-02,\n",
      "        -1.8823e-02,  2.9234e-02,  1.4646e-02, -3.2890e-02,  2.7924e-02,\n",
      "         2.2743e-02, -3.3038e-02, -5.1608e-03,  1.2183e-02,  4.3109e-03,\n",
      "         2.0557e-02,  1.9714e-02, -5.7884e-03,  1.0712e-02,  3.8083e-03,\n",
      "        -1.2079e-02, -6.8209e-03, -9.3506e-04, -3.8965e-03, -2.5683e-02,\n",
      "        -2.2573e-02, -3.5288e-02,  4.7688e-03,  2.4231e-02, -6.0958e-03,\n",
      "        -2.8891e-02, -3.3468e-02,  2.9872e-02, -7.7942e-03,  2.3457e-02,\n",
      "         1.7859e-02,  3.4933e-02, -1.1933e-02, -4.1945e-03,  2.9683e-02,\n",
      "         1.9557e-02, -6.5409e-03,  3.5673e-03,  1.4669e-03, -5.0600e-03,\n",
      "         3.1266e-02, -1.7866e-02,  2.8279e-03, -2.1646e-02,  2.1021e-02,\n",
      "         1.1404e-02,  8.6160e-03,  2.6103e-02,  1.1285e-02, -5.2470e-03,\n",
      "         5.8441e-03,  1.4979e-02,  3.2557e-02,  1.7715e-03, -3.1104e-03,\n",
      "         1.1499e-02, -3.5911e-02,  7.3520e-03,  1.1824e-02,  8.2500e-03,\n",
      "        -3.3354e-03, -1.6531e-02, -5.1706e-03, -6.1930e-03,  1.3714e-02,\n",
      "        -1.7934e-03,  3.4504e-03,  1.4423e-02, -3.5108e-02, -2.2218e-02,\n",
      "         3.2388e-02, -1.2304e-02,  5.6561e-03,  6.9724e-03, -3.4936e-02,\n",
      "        -1.8501e-02, -1.3480e-02, -5.5582e-03, -3.5267e-02,  1.5496e-02,\n",
      "         1.6493e-02, -2.7143e-02, -2.6985e-02, -1.4272e-03,  6.8521e-03,\n",
      "        -8.4266e-03, -3.0795e-02, -2.7039e-02, -3.0596e-03,  1.0125e-02,\n",
      "        -2.1873e-03,  2.1969e-04, -3.1038e-02, -2.0460e-02,  9.5154e-03,\n",
      "        -3.2301e-02,  4.9988e-03,  1.1042e-03,  3.0632e-02, -9.9349e-03,\n",
      "        -2.2800e-02,  3.4840e-02, -2.4756e-02,  1.8187e-02,  4.6711e-03,\n",
      "         3.1982e-02, -1.5631e-02,  2.0239e-02, -2.1501e-02,  5.5910e-03,\n",
      "        -3.3788e-02,  1.1894e-02,  7.8313e-03,  1.3229e-03, -2.6324e-02,\n",
      "        -8.8155e-03, -1.9944e-02, -3.1573e-02,  3.5526e-02,  8.2345e-05,\n",
      "         2.9560e-02,  1.1534e-02, -3.3070e-03, -1.2757e-02,  8.1976e-03,\n",
      "         2.2361e-02,  2.6521e-02,  6.9026e-04, -2.6735e-02, -5.3634e-04,\n",
      "         1.3622e-02, -9.3163e-03,  3.5929e-02, -8.6354e-03,  3.0544e-02,\n",
      "         1.5627e-02,  1.8202e-02,  3.3912e-02,  7.6259e-03, -2.5245e-02,\n",
      "         2.4139e-02,  1.1341e-03,  2.2278e-02,  3.3731e-02,  2.8255e-02,\n",
      "        -1.9548e-02,  9.6101e-03,  1.7964e-03, -2.9608e-02,  2.3939e-02,\n",
      "         2.3684e-02, -2.4731e-02, -3.4661e-02,  1.9385e-02,  2.5198e-02,\n",
      "        -1.1720e-02,  1.0954e-02, -2.1580e-02, -1.3106e-02,  3.6058e-02,\n",
      "         4.8010e-03, -3.0395e-03, -1.7384e-02, -2.3810e-02,  2.1205e-02,\n",
      "         4.8745e-03, -2.3812e-03,  1.6971e-02,  3.2686e-02, -2.5348e-03,\n",
      "         1.1973e-02, -1.9031e-02, -1.1876e-02, -1.0925e-02, -2.3856e-02,\n",
      "         2.9625e-02,  7.7511e-03, -2.0868e-02, -3.5518e-02,  2.6784e-02,\n",
      "         1.3618e-03,  2.5466e-02, -1.4153e-02,  2.4176e-02,  2.8694e-02,\n",
      "        -2.1139e-02, -3.3506e-02,  3.3425e-02, -1.7226e-02,  9.7569e-03,\n",
      "        -2.7978e-02,  7.5912e-03, -6.9159e-03,  2.8094e-02,  2.6129e-02,\n",
      "        -1.2834e-02, -5.4318e-03,  3.5024e-03,  2.3620e-02,  3.3628e-02,\n",
      "        -3.2637e-02, -5.8067e-03, -3.3805e-03,  3.0130e-02, -7.9638e-03,\n",
      "        -8.9510e-03,  1.4241e-02, -1.9301e-02, -3.2581e-02,  2.8407e-02,\n",
      "         2.1242e-02,  1.2903e-02, -1.8302e-02, -1.1459e-02,  2.1956e-02,\n",
      "         1.4608e-02, -2.0014e-02, -3.4417e-02,  3.5243e-02, -2.8940e-02,\n",
      "        -3.2992e-02, -4.4792e-03, -6.2184e-03,  2.3435e-02,  5.0073e-03,\n",
      "         2.1245e-02, -2.8781e-02,  2.6524e-03, -3.5664e-02, -9.3244e-03,\n",
      "        -2.1847e-02, -7.7996e-03,  2.8039e-02,  1.3747e-02, -2.8616e-02,\n",
      "        -1.3222e-02,  2.1978e-02,  7.3225e-03, -3.0084e-02, -2.1751e-02,\n",
      "         2.3505e-02, -8.0505e-03, -3.0933e-02, -3.1789e-02, -1.2761e-02,\n",
      "        -1.6112e-02, -7.9952e-03,  1.1372e-02,  2.2331e-02,  6.3739e-03,\n",
      "         1.8341e-02,  1.9120e-02, -2.7166e-02, -3.2219e-02,  2.3174e-02,\n",
      "         1.3596e-02,  3.4367e-02,  1.5632e-02, -3.0068e-02,  2.2209e-02,\n",
      "        -2.5914e-02, -2.3877e-03, -9.9571e-03, -1.0172e-02,  3.9222e-03,\n",
      "         2.7682e-02,  2.1978e-02, -1.8691e-02,  2.6430e-02, -1.7719e-02,\n",
      "        -2.4995e-02, -2.8560e-02, -2.6738e-03,  2.7495e-02,  3.4358e-02,\n",
      "        -2.4945e-02, -2.2925e-03,  2.8615e-02, -5.9179e-03,  3.0588e-02,\n",
      "         1.4379e-02,  1.3859e-03, -1.6319e-02, -1.4690e-02,  2.6818e-02,\n",
      "        -2.5462e-03,  4.1743e-03,  2.1862e-02,  1.9760e-02, -2.6148e-02,\n",
      "        -1.8616e-02,  1.3402e-02, -3.4647e-03, -1.0672e-03,  2.5337e-02,\n",
      "        -3.5201e-02, -1.6607e-02,  1.2077e-02,  2.1497e-02,  3.3026e-02,\n",
      "        -9.3562e-03,  2.5621e-02,  1.6804e-02,  1.6713e-02,  3.4122e-02,\n",
      "         2.2612e-02,  2.3814e-03,  2.7297e-02, -2.8349e-02,  5.6281e-03,\n",
      "         1.2784e-03,  3.0868e-02, -1.9422e-02,  2.9334e-02,  3.6613e-03,\n",
      "         2.8220e-02,  1.7023e-02,  2.8022e-02,  2.2578e-02,  1.4724e-02,\n",
      "        -1.6051e-02, -2.5834e-02, -1.7348e-02,  3.0281e-02, -1.3001e-02,\n",
      "        -2.7492e-02, -2.2113e-02, -2.6182e-02,  6.0126e-03,  1.8430e-02,\n",
      "         2.6093e-02,  2.8845e-02, -1.2345e-02, -2.0765e-02,  1.9962e-02,\n",
      "         2.6238e-02, -2.2011e-02,  1.9121e-02, -2.5221e-02,  2.7129e-02,\n",
      "        -2.5199e-02, -3.1175e-02, -6.1148e-03, -2.2116e-02, -1.3658e-02,\n",
      "         1.1824e-02, -1.5037e-02,  2.6742e-02,  1.7196e-02, -2.2188e-02,\n",
      "        -1.6807e-03,  2.7409e-02, -1.2414e-02, -9.5285e-03,  9.3241e-03,\n",
      "         8.4117e-03,  9.3611e-03,  1.9098e-02,  2.4674e-02,  2.0299e-02,\n",
      "         3.3249e-02,  3.2102e-02,  3.7297e-03,  1.3781e-02,  1.2731e-02,\n",
      "         1.1293e-02,  2.7260e-02, -1.9958e-02, -2.8903e-02,  1.8188e-02,\n",
      "        -3.0742e-02, -6.4261e-03,  7.3568e-03, -3.3681e-04,  3.3746e-02,\n",
      "         1.2963e-02,  3.4623e-02, -2.3521e-02,  1.4796e-02,  7.8591e-03,\n",
      "        -1.4406e-02,  3.9235e-03, -1.6135e-02, -2.2119e-02,  2.2031e-02,\n",
      "        -8.3480e-03,  8.8842e-03, -9.9500e-04, -1.6536e-02,  3.1409e-02,\n",
      "         4.9669e-03,  1.6265e-02, -3.5168e-02, -2.0794e-02,  1.9272e-02,\n",
      "        -1.1931e-02, -1.4143e-02,  6.5582e-03,  3.3592e-02, -2.0577e-02,\n",
      "        -2.5926e-04, -8.6513e-04,  1.0794e-02,  7.2978e-03,  2.1952e-02,\n",
      "         5.8887e-03, -5.8400e-03, -3.0095e-02, -1.9136e-02,  3.2607e-02,\n",
      "        -2.0192e-02,  3.2404e-02, -2.3333e-02,  2.7701e-02,  6.7707e-03,\n",
      "         1.2820e-02,  2.1960e-02, -2.7869e-03,  1.9941e-02,  2.7837e-02,\n",
      "         2.2067e-02, -2.6928e-02, -1.0144e-02,  5.2978e-03, -2.6920e-02,\n",
      "        -3.3337e-02, -2.9637e-02,  3.1166e-02, -2.0906e-02, -2.4237e-02,\n",
      "        -3.5509e-02,  1.7860e-02,  9.2312e-03, -1.6356e-02, -1.2183e-02,\n",
      "         3.5773e-02,  2.7803e-02,  3.2840e-02,  3.0947e-02,  1.1093e-02,\n",
      "        -2.4222e-02,  2.0747e-02, -1.5070e-02, -3.0203e-02, -1.7187e-02,\n",
      "        -2.3336e-02,  3.0090e-02, -1.2604e-02, -2.1848e-02, -3.3759e-03,\n",
      "         1.1390e-02, -8.0272e-03, -1.7467e-02, -2.6840e-02,  9.1613e-03,\n",
      "        -2.2507e-02, -3.3023e-02,  2.5524e-02, -6.7503e-03, -2.8445e-02,\n",
      "         5.2968e-03, -1.2023e-02,  1.8213e-02, -2.5630e-02,  3.2907e-03,\n",
      "         5.0301e-03,  2.0537e-02,  1.5869e-02, -2.0374e-02,  2.6418e-02,\n",
      "        -9.0380e-03, -1.2678e-02,  7.0099e-03, -1.9749e-02,  1.7096e-02,\n",
      "        -1.4936e-02,  4.7981e-03, -1.3253e-02, -1.9514e-02,  4.0377e-03,\n",
      "        -7.4690e-03,  3.5299e-02, -3.1666e-03,  1.0926e-02, -1.7091e-02,\n",
      "         1.4056e-02, -2.2502e-02,  1.3571e-02, -1.6239e-03,  3.0784e-02,\n",
      "        -2.3449e-02, -2.3265e-02, -2.0442e-02, -3.3922e-02, -7.7738e-04,\n",
      "         2.2203e-02, -2.6587e-02, -2.0156e-02,  2.3166e-02, -1.0301e-02,\n",
      "         2.4909e-03,  2.6617e-03,  1.7516e-02, -3.3309e-02,  1.0003e-02,\n",
      "        -2.5867e-03, -3.4455e-02,  6.4859e-03, -1.9905e-02, -2.2692e-02,\n",
      "        -1.5388e-02,  1.2576e-02,  6.9842e-03, -1.9875e-02, -1.7691e-02,\n",
      "        -3.2957e-03,  3.1505e-02,  2.6708e-02, -6.8155e-03, -1.3085e-03,\n",
      "        -2.6363e-02,  2.4870e-02,  8.2823e-03,  1.4863e-02,  6.3721e-03,\n",
      "         2.8987e-02, -1.7596e-02,  1.2543e-02,  3.5342e-02, -7.5044e-03,\n",
      "         1.9598e-02,  4.2358e-05, -1.9189e-02, -2.1436e-02, -2.2704e-02,\n",
      "        -1.8641e-04,  2.8793e-02, -9.9017e-03, -1.7413e-02, -3.1556e-02,\n",
      "         3.0480e-02, -1.6210e-02,  1.5408e-02,  1.6052e-02, -1.7206e-02,\n",
      "        -2.4306e-02, -9.3106e-03, -1.2105e-03,  9.5991e-04, -2.8160e-02,\n",
      "        -1.3527e-02,  3.0320e-02, -2.6192e-02,  1.3502e-03,  3.0951e-02,\n",
      "        -2.0324e-02,  8.9189e-03,  2.0187e-02,  2.8669e-02,  1.6679e-02,\n",
      "        -3.5552e-02,  1.3731e-02, -2.8545e-02,  1.5039e-02,  5.8682e-03,\n",
      "        -1.9729e-03,  2.5887e-02,  4.8830e-03,  2.7992e-02,  2.1791e-02,\n",
      "        -1.7148e-02,  1.6586e-02, -2.2400e-03, -2.4012e-02,  3.2258e-02,\n",
      "        -2.2598e-03,  6.5718e-03,  2.0139e-02,  5.6795e-03,  9.0758e-03,\n",
      "         3.3602e-02,  9.2955e-03,  4.5864e-03, -6.6152e-03,  1.5123e-02,\n",
      "        -9.1067e-03,  2.0499e-02, -2.5952e-02,  9.4745e-04,  2.4233e-02,\n",
      "        -2.7331e-03, -3.2519e-02, -1.0810e-02,  2.2762e-02, -2.5062e-02,\n",
      "         2.3571e-04,  7.8330e-03,  1.2927e-02, -1.3283e-02,  1.5181e-02,\n",
      "         5.6289e-03,  5.5081e-03, -3.7780e-03,  1.0859e-02, -1.5463e-02,\n",
      "         1.8956e-02,  2.0260e-02,  3.5792e-02, -1.6013e-02, -3.2703e-02,\n",
      "         3.0753e-02,  3.4164e-02, -3.3771e-02,  5.4314e-03,  1.6370e-04,\n",
      "        -2.9897e-04, -2.5623e-02, -1.5946e-03, -1.1012e-02,  1.5803e-02,\n",
      "        -1.4275e-02,  1.3804e-02,  7.4562e-03, -8.6995e-03, -2.9061e-03,\n",
      "        -2.1445e-02, -8.2828e-03, -8.3755e-03, -3.3246e-02, -2.5088e-03,\n",
      "        -1.2921e-02, -1.3801e-02,  1.5492e-02, -2.4137e-02, -2.2433e-02,\n",
      "        -2.4975e-02, -6.9314e-03, -2.6601e-03,  2.1409e-02, -2.2998e-02,\n",
      "         8.1080e-03, -2.9704e-02,  2.6310e-02,  9.4567e-04, -1.9146e-02,\n",
      "         1.8916e-02, -1.8968e-02, -2.2686e-02, -2.6505e-02,  7.9824e-03,\n",
      "         3.5461e-03, -1.9687e-03, -7.0065e-03], requires_grad=True)\n",
      "name:out_proj.bias torch.Size([768]) 768\n",
      "total_params_ff: 2360064\n"
     ]
    }
   ],
   "source": [
    "total_params_ff = 0\n",
    "for name, param in block.att.named_parameters():\n",
    "    print(f\"param: {param}\")\n",
    "    print(f\"name:{name} {param.shape} {param.numel()}\")\n",
    "    total_params_ff += param.numel()\n",
    "\n",
    "print(f\"total_params_ff: {total_params_ff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5be37cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create a simple linear layer\n",
    "linear = nn.Linear(in_features=10, out_features=5, bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a026576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        Parameter\n",
      "\u001b[0;31mString form:\u001b[0m\n",
      "Parameter containing:\n",
      "           tensor([[ 0.2548,  0.1334, -0.0462,  0.0847, -0.0305, -0.1611,  0.1566, -0. <...> 52,  0.2111, -0.1356,  0.1570, -0.2800, -0.2906,\n",
      "           -0.0413, -0.0559]], requires_grad=True)\n",
      "\u001b[0;31mLength:\u001b[0m      5\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/pytorch_gpu_0710/lib/python3.10/site-packages/torch/nn/parameter.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "A kind of Tensor that is to be considered a module parameter.\n",
      "\n",
      "Parameters are :class:`~torch.Tensor` subclasses, that have a\n",
      "very special property when used with :class:`Module` s - when they're\n",
      "assigned as Module attributes they are automatically added to the list of\n",
      "its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.\n",
      "Assigning a Tensor doesn't have such effect. This is because one might\n",
      "want to cache some temporary state, like last hidden state of the RNN, in\n",
      "the model. If there was no such class as :class:`Parameter`, these\n",
      "temporaries would get registered too.\n",
      "\n",
      "Args:\n",
      "    data (Tensor): parameter tensor.\n",
      "    requires_grad (bool, optional): if the parameter requires gradient. Note that\n",
      "        the torch.no_grad() context does NOT affect the default behavior of\n",
      "        Parameter creation--the Parameter will still have `requires_grad=True` in\n",
      "        :class:`~no_grad` mode. See :ref:`locally-disable-grad-doc` for more\n",
      "        details. Default: `True`"
     ]
    }
   ],
   "source": [
    "linear.weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18c5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_0710",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
