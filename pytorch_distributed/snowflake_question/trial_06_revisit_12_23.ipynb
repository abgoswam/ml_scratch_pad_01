{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c2f7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d54ca8108d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5d133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    return nn.Linear(4,2, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c8fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [make_model(), make_model()]\n",
    "opt = optim.Adam(models[0].parameters(), lr=0.1)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# dummy input batches for each replica\n",
    "x1, y1 = torch.randn(5,4), torch.randn(5,2)\n",
    "x2, y2 = torch.randn(5,4), torch.randn(5,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a94b04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Linear(in_features=4, out_features=2, bias=True)===\n",
      "  weight: shape torch.Size([2, 4]), requires_grad=True\n",
      "tensor([[ 0.3823,  0.4150, -0.1171,  0.4593],\n",
      "        [-0.1096,  0.1009, -0.2434,  0.2936]])\n",
      "None\n",
      "  bias: shape torch.Size([2]), requires_grad=True\n",
      "tensor([ 0.4408, -0.3668])\n",
      "None\n",
      "==Linear(in_features=4, out_features=2, bias=True)===\n",
      "  weight: shape torch.Size([2, 4]), requires_grad=True\n",
      "tensor([[ 0.4346,  0.0936,  0.3694,  0.0677],\n",
      "        [ 0.2411, -0.0706,  0.3854,  0.0739]])\n",
      "None\n",
      "  bias: shape torch.Size([2]), requires_grad=True\n",
      "tensor([-0.2334,  0.1274])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print(f\"=={m}===\")\n",
    "    for name, param in m.named_parameters():\n",
    "        print(f\"  {name}: shape {param.shape}, requires_grad={param.requires_grad}\")\n",
    "        print(param.data)\n",
    "        print(param.grad)\n",
    "\n",
    "\n",
    "    # print(m.weight)\n",
    "    # print(m.bias)\n",
    "    # print(m.weight.grad)\n",
    "    # print(m.bias.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2027831",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, (x, y) in zip(models, [(x1, y1), (x2, y2)]):\n",
    "    out = m(x)\n",
    "    loss = loss_fn(out, y)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8beb4679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Linear(in_features=4, out_features=2, bias=True)===\n",
      "  weight: shape torch.Size([2, 4]), requires_grad=True\n",
      "tensor([[ 0.3823,  0.4150, -0.1171,  0.4593],\n",
      "        [-0.1096,  0.1009, -0.2434,  0.2936]])\n",
      "tensor([[-0.5501,  0.8377, -0.0246,  1.3850],\n",
      "        [-0.7417, -0.0662, -0.2327,  0.9729]])\n",
      "  bias: shape torch.Size([2]), requires_grad=True\n",
      "tensor([ 0.4408, -0.3668])\n",
      "tensor([ 0.9726, -0.4391])\n",
      "==Linear(in_features=4, out_features=2, bias=True)===\n",
      "  weight: shape torch.Size([2, 4]), requires_grad=True\n",
      "tensor([[ 0.4346,  0.0936,  0.3694,  0.0677],\n",
      "        [ 0.2411, -0.0706,  0.3854,  0.0739]])\n",
      "tensor([[ 0.0956,  0.0095, -0.3197,  0.0189],\n",
      "        [-0.1313, -0.1836,  0.0369, -0.1920]])\n",
      "  bias: shape torch.Size([2]), requires_grad=True\n",
      "tensor([-0.2334,  0.1274])\n",
      "tensor([-0.2163, -0.3139])\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print(f\"=={m}===\")\n",
    "    for name, param in m.named_parameters():\n",
    "        print(f\"  {name}: shape {param.shape}, requires_grad={param.requires_grad}\")\n",
    "        print(param.data)\n",
    "        print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82678161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 params: Parameter containing:\n",
      "tensor([[ 0.3823,  0.4150, -0.1171,  0.4593],\n",
      "        [-0.1096,  0.1009, -0.2434,  0.2936]], requires_grad=True)\n",
      "i: 1 params: Parameter containing:\n",
      "tensor([ 0.4408, -0.3668], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i, params in enumerate(models[0].parameters()):\n",
    "    print(f\"i: {i} params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f25e58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "num_params = len(list(models[0].parameters()))\n",
    "print(num_params)\n",
    "\n",
    "num_models = len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df78bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_with_parameters = []\n",
    "\n",
    "for m in models:\n",
    "    params = list(m.parameters())\n",
    "    models_with_parameters.append(params)\n",
    "\n",
    "for i in range(num_params):\n",
    "\n",
    "    new_grad = models_with_parameters[0][i].grad\n",
    "    for j in range(1, num_models):\n",
    "        new_grad += models_with_parameters[j][i].grad\n",
    "\n",
    "    new_grad /= num_models\n",
    "\n",
    "    for j in range(num_models):\n",
    "        models_with_parameters[j][i].grad = new_grad\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de4ca9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Linear(in_features=4, out_features=2, bias=True)===\n",
      "  weight: shape torch.Size([2, 4]), requires_grad=True\n",
      "tensor([[ 0.3823,  0.4150, -0.1171,  0.4593],\n",
      "        [-0.1096,  0.1009, -0.2434,  0.2936]])\n",
      "tensor([[-0.2273,  0.4236, -0.1722,  0.7019],\n",
      "        [-0.4365, -0.1249, -0.0979,  0.3905]])\n",
      "  bias: shape torch.Size([2]), requires_grad=True\n",
      "tensor([ 0.4408, -0.3668])\n",
      "tensor([ 0.3782, -0.3765])\n",
      "==Linear(in_features=4, out_features=2, bias=True)===\n",
      "  weight: shape torch.Size([2, 4]), requires_grad=True\n",
      "tensor([[ 0.4346,  0.0936,  0.3694,  0.0677],\n",
      "        [ 0.2411, -0.0706,  0.3854,  0.0739]])\n",
      "tensor([[-0.2273,  0.4236, -0.1722,  0.7019],\n",
      "        [-0.4365, -0.1249, -0.0979,  0.3905]])\n",
      "  bias: shape torch.Size([2]), requires_grad=True\n",
      "tensor([-0.2334,  0.1274])\n",
      "tensor([ 0.3782, -0.3765])\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print(f\"=={m}===\")\n",
    "    for name, param in m.named_parameters():\n",
    "        print(f\"  {name}: shape {param.shape}, requires_grad={param.requires_grad}\")\n",
    "        print(param.data)\n",
    "        print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "338d44e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6270, -1.3951, -0.2387, -0.5050],\n",
      "        [-2.4752, -0.9316, -0.1335,  0.3415]])\n",
      "tensor([[-0.6270, -0.3951,  0.7613,  0.4950],\n",
      "        [-1.4752,  0.0684,  0.8665,  1.3415]])\n",
      "tensor([[-1.6270, -1.3951, -0.2387, -0.5050],\n",
      "        [-2.4752, -0.9316, -0.1335,  0.3415]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,4)\n",
    "y = x.clone()\n",
    "\n",
    "\n",
    "print(x)\n",
    "x += 1\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f4db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e80c30cb",
   "metadata": {},
   "source": [
    "## Stack Approach - Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbf17b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensors:\n",
      "tensor1: tensor([1., 2., 3.])\n",
      "tensor2: tensor([4., 5., 6.])\n",
      "tensor3: tensor([7., 8., 9.])\n",
      "\n",
      "Stacked shape: torch.Size([3, 3])\n",
      "Stacked tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "\n",
      "Averaged (mean along dim 0): tensor([4., 5., 6.])\n",
      "Manual check: [(1+4+7)/3, (2+5+8)/3, (3+6+9)/3] = tensor([4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# First, let's understand torch.stack with a simple example\n",
    "# Stack takes a list of tensors and stacks them into a new dimension\n",
    "\n",
    "tensor1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "tensor2 = torch.tensor([4.0, 5.0, 6.0])\n",
    "tensor3 = torch.tensor([7.0, 8.0, 9.0])\n",
    "\n",
    "print(\"Original tensors:\")\n",
    "print(f\"tensor1: {tensor1}\")\n",
    "print(f\"tensor2: {tensor2}\")\n",
    "print(f\"tensor3: {tensor3}\")\n",
    "\n",
    "# Stack them along dimension 0 (creates a new dimension)\n",
    "stacked = torch.stack([tensor1, tensor2, tensor3])\n",
    "print(f\"\\nStacked shape: {stacked.shape}\")  # Should be [3, 3]\n",
    "print(f\"Stacked tensor:\\n{stacked}\")\n",
    "\n",
    "# Now compute mean along the first dimension (across tensors)\n",
    "averaged = stacked.mean(dim=0)\n",
    "print(f\"\\nAveraged (mean along dim 0): {averaged}\")\n",
    "print(f\"Manual check: [(1+4+7)/3, (2+5+8)/3, (3+6+9)/3] = {torch.tensor([4.0, 5.0, 6.0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3973fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before averaging:\n",
      "Model 0 weight.grad shape: torch.Size([2, 4])\n",
      "Model 0 weight.grad[0, :3]: tensor([-0.5501,  0.8377, -0.0246])\n",
      "Model 1 weight.grad[0, :3]: tensor([ 0.0956,  0.0095, -0.3197])\n",
      "\n",
      "Model 0 bias.grad: tensor([ 0.9726, -0.4391])\n",
      "Model 1 bias.grad: tensor([-0.2163, -0.3139])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Now apply this to gradient averaging\n",
    "# Create fresh models with gradients\n",
    "models_stack = [make_model(), make_model()]\n",
    "\n",
    "for m, (x, y) in zip(models_stack, [(x1, y1), (x2, y2)]):\n",
    "    out = m(x)\n",
    "    loss = loss_fn(out, y)\n",
    "    loss.backward()\n",
    "\n",
    "print(\"Before averaging:\")\n",
    "print(f\"Model 0 weight.grad shape: {models_stack[0].weight.grad.shape}\")\n",
    "print(f\"Model 0 weight.grad[0, :3]: {models_stack[0].weight.grad[0, :3]}\")\n",
    "print(f\"Model 1 weight.grad[0, :3]: {models_stack[1].weight.grad[0, :3]}\")\n",
    "print(f\"\\nModel 0 bias.grad: {models_stack[0].bias.grad}\")\n",
    "print(f\"Model 1 bias.grad: {models_stack[1].bias.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4030460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual gradients:\n",
      "grad0 shape: torch.Size([2, 4])\n",
      "grad1 shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Stack approach for weight parameter\n",
    "# Collect gradients from both models\n",
    "grad0 = models_stack[0].weight.grad  # Shape: [2, 4]\n",
    "grad1 = models_stack[1].weight.grad  # Shape: [2, 4]\n",
    "\n",
    "print(\"Individual gradients:\")\n",
    "print(f\"grad0 shape: {grad0.shape}\")\n",
    "print(f\"grad1 shape: {grad1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da91701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacked shape: torch.Size([2, 2, 4])\n",
      "Stacked[0] is grad0: True\n",
      "Stacked[1] is grad1: True\n"
     ]
    }
   ],
   "source": [
    "# Stack them - creates a new dimension at position 0\n",
    "stacked_grads = torch.stack([grad0, grad1])\n",
    "print(f\"\\nStacked shape: {stacked_grads.shape}\")  # Should be [2, 2, 4]\n",
    "print(f\"Stacked[0] is grad0: {torch.equal(stacked_grads[0], grad0)}\")\n",
    "print(f\"Stacked[1] is grad1: {torch.equal(stacked_grads[1], grad1)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edd769ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5501,  0.8377, -0.0246,  1.3850],\n",
       "         [-0.7417, -0.0662, -0.2327,  0.9729]],\n",
       "\n",
       "        [[ 0.0956,  0.0095, -0.3197,  0.0189],\n",
       "         [-0.1313, -0.1836,  0.0369, -0.1920]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f739bd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Averaged gradient shape: torch.Size([2, 4])\n",
      "Averaged gradient[0, :3]: tensor([-0.2273,  0.4236, -0.1722])\n",
      "\n",
      "Manual average[0, :3]: tensor([-0.2273,  0.4236, -0.1722])\n",
      "Results match: True\n"
     ]
    }
   ],
   "source": [
    "# Average along dimension 0 (across models)\n",
    "avg_grad = stacked_grads.mean(dim=0)\n",
    "print(f\"\\nAveraged gradient shape: {avg_grad.shape}\")  # Back to [2, 4]\n",
    "print(f\"Averaged gradient[0, :3]: {avg_grad[0, :3]}\")\n",
    "\n",
    "# Verify it's actually the mean\n",
    "manual_avg = (grad0 + grad1) / 2\n",
    "print(f\"\\nManual average[0, :3]: {manual_avg[0, :3]}\")\n",
    "print(f\"Results match: {torch.allclose(avg_grad, manual_avg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffe1454f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After averaging (stack approach):\n",
      "Model 0 weight.grad[0, :3]: tensor([-0.2273,  0.4236, -0.1722])\n",
      "Model 1 weight.grad[0, :3]: tensor([-0.2273,  0.4236, -0.1722])\n",
      "\n",
      "Model 0 bias.grad: tensor([ 0.3782, -0.3765])\n",
      "Model 1 bias.grad: tensor([ 0.3782, -0.3765])\n",
      "\n",
      "Both models now have identical gradients!\n"
     ]
    }
   ],
   "source": [
    "# Complete implementation using stack approach\n",
    "def average_gradients_stack(models):\n",
    "    \"\"\"Average gradients across models using torch.stack\"\"\"\n",
    "    num_params = len(list(models[0].parameters()))\n",
    "    \n",
    "    for param_idx in range(num_params):\n",
    "        # Collect all gradients for this parameter across all models\n",
    "        grads = [list(m.parameters())[param_idx].grad for m in models]\n",
    "        \n",
    "        # Stack them into a single tensor and compute mean\n",
    "        avg_grad = torch.stack(grads).mean(dim=0)\n",
    "        \n",
    "        # Assign averaged gradient back to all models\n",
    "        for m in models:\n",
    "            list(m.parameters())[param_idx].grad = avg_grad\n",
    "\n",
    "# Apply to our models\n",
    "average_gradients_stack(models_stack)\n",
    "\n",
    "print(\"After averaging (stack approach):\")\n",
    "print(f\"Model 0 weight.grad[0, :3]: {models_stack[0].weight.grad[0, :3]}\")\n",
    "print(f\"Model 1 weight.grad[0, :3]: {models_stack[1].weight.grad[0, :3]}\")\n",
    "print(f\"\\nModel 0 bias.grad: {models_stack[0].bias.grad}\")\n",
    "print(f\"Model 1 bias.grad: {models_stack[1].bias.grad}\")\n",
    "print(\"\\nBoth models now have identical gradients!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b57b2553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before averaging:\n",
      "Model 0 weight.grad shape: torch.Size([2, 4])\n",
      "Model 0 weight.grad[0, :3]: tensor([-0.5501,  0.8377, -0.0246])\n",
      "Model 1 weight.grad[0, :3]: tensor([ 0.0956,  0.0095, -0.3197])\n",
      "\n",
      "Model 0 bias.grad: tensor([ 0.9726, -0.4391])\n",
      "Model 1 bias.grad: tensor([-0.2163, -0.3139])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Now apply this to gradient averaging\n",
    "# Create fresh models with gradients\n",
    "models_stack = [make_model(), make_model()]\n",
    "\n",
    "for m, (x, y) in zip(models_stack, [(x1, y1), (x2, y2)]):\n",
    "    out = m(x)\n",
    "    loss = loss_fn(out, y)\n",
    "    loss.backward()\n",
    "\n",
    "print(\"Before averaging:\")\n",
    "print(f\"Model 0 weight.grad shape: {models_stack[0].weight.grad.shape}\")\n",
    "print(f\"Model 0 weight.grad[0, :3]: {models_stack[0].weight.grad[0, :3]}\")\n",
    "print(f\"Model 1 weight.grad[0, :3]: {models_stack[1].weight.grad[0, :3]}\")\n",
    "print(f\"\\nModel 0 bias.grad: {models_stack[0].bias.grad}\")\n",
    "print(f\"Model 1 bias.grad: {models_stack[1].bias.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1927263c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After averaging (stack approach):\n",
      "Model 0 weight.grad[0, :3]: tensor([-0.2273,  0.4236, -0.1722])\n",
      "Model 1 weight.grad[0, :3]: tensor([-0.2273,  0.4236, -0.1722])\n",
      "\n",
      "Model 0 bias.grad: tensor([ 0.3782, -0.3765])\n",
      "Model 1 bias.grad: tensor([ 0.3782, -0.3765])\n",
      "models have identical gradients?: True\n"
     ]
    }
   ],
   "source": [
    "# Complete implementation using stack approach\n",
    "def average_gradients_stack_2(models):\n",
    "    \"\"\"Average gradients across models using torch.stack\"\"\"\n",
    "    num_params = len(list(models[0].parameters()))\n",
    "    \n",
    "    for param_idx in range(num_params):\n",
    "\n",
    "        # pid_shape = list(models[0].parameters())[param_idx].grad.shape\n",
    "        # print(pid_shape)\n",
    "\n",
    "        init = torch.zeros_like(list(models[0].parameters())[param_idx].grad)\n",
    "\n",
    "        for m in models:\n",
    "            init += list(m.parameters())[param_idx].grad\n",
    "\n",
    "        init /= len(models)\n",
    "       \n",
    "        # Assign averaged gradient back to all models\n",
    "        for m in models:\n",
    "            list(m.parameters())[param_idx].grad = init\n",
    "\n",
    "# Apply to our models\n",
    "average_gradients_stack_2(models_stack)\n",
    "\n",
    "print(\"After averaging (stack approach):\")\n",
    "print(f\"Model 0 weight.grad[0, :3]: {models_stack[0].weight.grad[0, :3]}\")\n",
    "print(f\"Model 1 weight.grad[0, :3]: {models_stack[1].weight.grad[0, :3]}\")\n",
    "print(f\"\\nModel 0 bias.grad: {models_stack[0].bias.grad}\")\n",
    "print(f\"Model 1 bias.grad: {models_stack[1].bias.grad}\")\n",
    "\n",
    "is_equal = torch.equal(models_stack[0].bias.grad, models_stack[1].bias.grad)\n",
    "print(f\"models have identical gradients?: {is_equal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68bdb05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "095a6c3a",
   "metadata": {},
   "source": [
    "## torch.equal() Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bd0dee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors:\n",
      "a = tensor([1, 2, 3])\n",
      "b = tensor([1, 2, 3])\n",
      "c = tensor([1, 2, 4])\n",
      "d = tensor([1, 2])\n",
      "\n",
      "Comparisons:\n",
      "torch.equal(a, b) = True\n",
      "torch.equal(a, c) = False\n",
      "torch.equal(a, d) = False\n",
      "\n",
      "torch.equal(x, y) = True\n",
      "torch.equal(x, z) = True\n"
     ]
    }
   ],
   "source": [
    "# torch.equal() checks if two tensors have the same shape and elements\n",
    "# Returns True/False (single boolean value)\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([1, 2, 3])\n",
    "c = torch.tensor([1, 2, 4])  # Different last element\n",
    "d = torch.tensor([1, 2])     # Different shape\n",
    "\n",
    "print(\"Tensors:\")\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "print(f\"c = {c}\")\n",
    "print(f\"d = {d}\")\n",
    "\n",
    "print(\"\\nComparisons:\")\n",
    "print(f\"torch.equal(a, b) = {torch.equal(a, b)}\")  # True - same shape and values\n",
    "print(f\"torch.equal(a, c) = {torch.equal(a, c)}\")  # False - different values\n",
    "print(f\"torch.equal(a, d) = {torch.equal(a, d)}\")  # False - different shapes\n",
    "\n",
    "# Works with any tensor shape\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "y = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "z = x.clone()  # Creates a copy\n",
    "\n",
    "print(f\"\\ntorch.equal(x, y) = {torch.equal(x, y)}\")  # True\n",
    "print(f\"torch.equal(x, z) = {torch.equal(x, z)}\")  # True - clone creates exact copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08fb97c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using == (element-wise):\n",
      "a == b = tensor([ True,  True, False])\n",
      "\n",
      "Using torch.equal (whole tensor):\n",
      "torch.equal(a, b) = False\n",
      "\n",
      "(a == b).all() = False\n"
     ]
    }
   ],
   "source": [
    "# Contrast with == operator (element-wise comparison)\n",
    "# == returns a tensor of booleans, torch.equal returns single boolean\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([1, 2, 4])\n",
    "\n",
    "print(\"Using == (element-wise):\")\n",
    "print(f\"a == b = {a == b}\")  # Returns tensor([True, True, False])\n",
    "\n",
    "print(\"\\nUsing torch.equal (whole tensor):\")\n",
    "print(f\"torch.equal(a, b) = {torch.equal(a, b)}\")  # Returns False\n",
    "\n",
    "# To check if all elements match using ==, you need .all()\n",
    "print(f\"\\n(a == b).all() = {(a == b).all()}\")  # False - same as torch.equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387a3d2",
   "metadata": {},
   "source": [
    "## torch.zeros() vs torch.zeros_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceea718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference tensor shape: torch.Size([2, 3])\n",
      "Reference tensor dtype: torch.float32\n",
      "Reference:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "torch.zeros(2, 3):\n",
      "  Shape: torch.Size([2, 3])\n",
      "  Dtype: torch.float32\n",
      "  Values:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "torch.zeros_like(reference):\n",
      "  Shape: torch.Size([2, 3])\n",
      "  Dtype: torch.float32\n",
      "  Values:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.zeros() - You manually specify the shape\n",
    "# torch.zeros_like() - Automatically matches shape of another tensor\n",
    "\n",
    "# Create a reference tensor\n",
    "reference = torch.tensor([[1.0, 2.0, 3.0], \n",
    "                          [4.0, 5.0, 6.0]])\n",
    "print(f\"Reference tensor shape: {reference.shape}\")\n",
    "print(f\"Reference tensor dtype: {reference.dtype}\")\n",
    "print(f\"Reference:\\n{reference}\\n\")\n",
    "\n",
    "# Method 1: torch.zeros() - Manual specification\n",
    "zeros_manual = torch.zeros(2, 3)  # Must specify shape explicitly\n",
    "print(f\"torch.zeros(2, 3):\")\n",
    "print(f\"  Shape: {zeros_manual.shape}\")\n",
    "print(f\"  Dtype: {zeros_manual.dtype}\")\n",
    "print(f\"  Values:\\n{zeros_manual}\\n\")\n",
    "\n",
    "# Method 2: torch.zeros_like() - Automatic from reference\n",
    "zeros_auto = torch.zeros_like(reference)  # Automatically gets shape & dtype\n",
    "print(f\"torch.zeros_like(reference):\")\n",
    "print(f\"  Shape: {zeros_auto.shape}\")  # Matches reference!\n",
    "print(f\"  Dtype: {zeros_auto.dtype}\")  # Matches reference!\n",
    "print(f\"  Values:\\n{zeros_auto}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ec88b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(reference.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key advantage: zeros_like() also preserves dtype and device\n",
    "\n",
    "# Integer tensor\n",
    "int_tensor = torch.tensor([[1, 2, 3]], dtype=torch.int32)\n",
    "zeros_int = torch.zeros_like(int_tensor)\n",
    "print(f\"int_tensor dtype: {int_tensor.dtype}\")\n",
    "print(f\"zeros_like dtype: {zeros_int.dtype}\")  # Also int32!\n",
    "print(f\"zeros_int: {zeros_int}\\n\")\n",
    "\n",
    "# Float16 tensor (half precision)\n",
    "half_tensor = torch.tensor([[1.0, 2.0]], dtype=torch.float16)\n",
    "zeros_half = torch.zeros_like(half_tensor)\n",
    "print(f\"half_tensor dtype: {half_tensor.dtype}\")\n",
    "print(f\"zeros_like dtype: {zeros_half.dtype}\")  # Also float16!\n",
    "\n",
    "# If you used zeros(), you'd have to manually specify dtype\n",
    "zeros_manual_wrong = torch.zeros(1, 2)  # Defaults to float32\n",
    "print(f\"\\ntorch.zeros(1, 2) dtype: {zeros_manual_wrong.dtype}\")  # float32 (wrong!)\n",
    "\n",
    "# You'd need to do this instead:\n",
    "zeros_manual_correct = torch.zeros(1, 2, dtype=torch.float16)\n",
    "print(f\"torch.zeros(1, 2, dtype=torch.float16) dtype: {zeros_manual_correct.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f72022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why use zeros_like() in gradient averaging?\n",
    "# It ensures the accumulator matches the gradient's properties exactly\n",
    "\n",
    "grad_example = models_stack[0].weight.grad  # Shape [2, 4], dtype float32\n",
    "print(f\"Gradient shape: {grad_example.shape}\")\n",
    "print(f\"Gradient dtype: {grad_example.dtype}\")\n",
    "\n",
    "# Using zeros_like() - automatically correct\n",
    "accumulator = torch.zeros_like(grad_example)\n",
    "print(f\"\\nAccumulator (zeros_like) shape: {accumulator.shape}\")\n",
    "print(f\"Accumulator (zeros_like) dtype: {accumulator.dtype}\")\n",
    "\n",
    "# Now we can safely add gradients\n",
    "accumulator += grad_example\n",
    "print(f\"\\nAfter adding gradient:\")\n",
    "print(f\"Accumulator[0, :3]: {accumulator[0, :3]}\")\n",
    "\n",
    "# This is safer than manually specifying:\n",
    "# accumulator = torch.zeros(2, 4)  # What if shape changes? What about dtype?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_0710",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
